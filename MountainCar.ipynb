{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipympl\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hahamark/.local/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('MountainCar-v0')\n",
    "env.seed(1); torch.manual_seed(1); np.random.seed(1)\n",
    "PATH = glob.glob(os.path.expanduser('~/tboardlogs/'))\n",
    "writer = SummaryWriter('{}{}'.format(PATH, datetime.now().strftime('%b%d_%H-%M-%S')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Furthest Position: -0.164068288377174\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful episodes: 0\n"
     ]
    }
   ],
   "source": [
    "max_position = -.4\n",
    "positions = np.ndarray([0,2])\n",
    "rewards = []\n",
    "successful = []\n",
    "for episode in range(1000):\n",
    "    running_reward = 0\n",
    "    env.reset()\n",
    "    done = False\n",
    "    for i in range(200):\n",
    "        state, reward, done, _ = env.step(np.random.randint(0,3))\n",
    "        # Give a reward for reaching a new maximum position\n",
    "        if state[0] > max_position:\n",
    "            max_position = state[0]\n",
    "            positions = np.append(positions, [[episode, max_position]], axis=0)\n",
    "            running_reward += 10\n",
    "        else:\n",
    "            running_reward += reward\n",
    "        if done: \n",
    "            if state[0] >= 0.5:\n",
    "                successful.append(episode)\n",
    "            rewards.append(running_reward)\n",
    "            break\n",
    "\n",
    "print('Furthest Position: {}'.format(max_position))\n",
    "plt.figure(1, figsize=[10,5])\n",
    "plt.subplot(211)\n",
    "plt.plot(positions[:,0], positions[:,1])\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Furthest Position')\n",
    "plt.subplot(212)\n",
    "plt.plot(rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.show()\n",
    "print('successful episodes: {}'.format(np.count_nonzero(successful)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried different weight initializations but found they did not perform well.\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight, 0, 1)\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.state_space = env.observation_space.shape[0]\n",
    "        self.action_space = env.action_space.n\n",
    "        self.hidden = 100\n",
    "        self.l1 = nn.Linear(self.state_space, self.hidden, bias=False)\n",
    "        self.l2 = nn.Linear(self.hidden, self.action_space, bias=False)\n",
    "    \n",
    "    def forward(self, x):    \n",
    "        model = torch.nn.Sequential(\n",
    "            self.l1,\n",
    "            self.l2,\n",
    "        )\n",
    "        return model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DQN(episodes):\n",
    "    \n",
    "    # Parameters\n",
    "    steps = 200\n",
    "    state = env.reset()\n",
    "    epsilon = 0.3\n",
    "    gamma = 0.99\n",
    "    loss_history = []\n",
    "    reward_history = []\n",
    "    learning_rate = 0.001\n",
    "    successes = 0\n",
    "    position = []\n",
    "\n",
    "    # Initialize Policy\n",
    "    policy = Policy()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD(policy.parameters(), lr=learning_rate)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    for episode in trange(episodes):\n",
    "        episode_loss = 0\n",
    "        episode_reward = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        for s in range(steps):\n",
    "            # Get first action value function\n",
    "            Q = policy(Variable(torch.from_numpy(state).type(torch.FloatTensor)))\n",
    "\n",
    "            # Choose epsilon-greedy action\n",
    "            if np.random.rand(1) < epsilon:\n",
    "                action = np.random.randint(0,3)\n",
    "            else:\n",
    "                _, action = torch.max(Q, -1)\n",
    "                action = action.item()\n",
    "\n",
    "            # Step forward and receive next state and reward\n",
    "            state_1, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Adjust reward based on car position\n",
    "            reward = state_1[0] + 0.5\n",
    "\n",
    "            # Adjust reward for task completion\n",
    "            if state_1[0] >= 0.5:\n",
    "                reward += 1\n",
    "\n",
    "            # Find max Q for t+1 state\n",
    "            Q1 = policy(Variable(torch.from_numpy(state_1).type(torch.FloatTensor)))\n",
    "            maxQ1, _ = torch.max(Q1, -1)\n",
    "\n",
    "            # Create target Q value for training the policy\n",
    "            Q_target = Q.clone()\n",
    "            Q_target = Variable(Q_target)\n",
    "            Q_target[action] = reward + torch.mul(maxQ1.detach(), gamma)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(Q, Q_target)\n",
    "\n",
    "            # Update policy\n",
    "            policy.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            episode_loss += loss.item()\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                if state_1[0] >= 0.5:\n",
    "                    # On successful epsisodes, adjust the following parameters\n",
    "                    # Adjust epsilon\n",
    "                    epsilon *= .95\n",
    "                    # Adjust learning rate\n",
    "                    scheduler.step()\n",
    "                    # Record successful episode\n",
    "                    successes += 1\n",
    "\n",
    "                # Record history\n",
    "                loss_history.append(episode_loss)\n",
    "                reward_history.append(episode_reward)\n",
    "                position.append(state_1[0])\n",
    "\n",
    "                break\n",
    "            else:\n",
    "                state = state_1\n",
    "                \n",
    "    print('successful episodes: {:d} - {:.4f}%'.format(successes, successes/episodes*100))\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DoubleDQN(episodes):\n",
    "    \n",
    "    # Parameters\n",
    "    steps = 200\n",
    "    state = env.reset()\n",
    "    epsilon = 0.3\n",
    "    gamma = 0.99\n",
    "    loss_history = []\n",
    "    reward_history = []\n",
    "    learning_rate = 0.001\n",
    "    successes = 0\n",
    "    position = []\n",
    "\n",
    "    # Initialize Policy\n",
    "    policy1 = Policy()\n",
    "    policy2 = Policy()\n",
    "    loss_fn = nn.MSELoss()\n",
    "    optimizer = optim.SGD([\n",
    "                {'params': policy1.parameters(), 'lr': learning_rate},\n",
    "                {'params': policy2.parameters(), 'lr': learning_rate}\n",
    "                ])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
    "\n",
    "    for episode in trange(episodes):\n",
    "        episode_loss = 0\n",
    "        episode_reward = 0\n",
    "        state = env.reset()\n",
    "\n",
    "        for s in range(steps):\n",
    "            # Get first action value function\n",
    "            turn1 = random.choice([True, False])\n",
    "            if turn1:\n",
    "                Q = policy1(Variable(torch.from_numpy(state).type(torch.FloatTensor)))\n",
    "            else:\n",
    "                Q = policy2(Variable(torch.from_numpy(state).type(torch.FloatTensor)))\n",
    "                \n",
    "            # Choose epsilon-greedy action\n",
    "            if np.random.rand(1) < epsilon:\n",
    "                action = np.random.randint(0,3)\n",
    "            else:\n",
    "                _, action = torch.max(Q, -1)\n",
    "                action = action.item()\n",
    "\n",
    "            # Step forward and receive next state and reward\n",
    "            state_1, reward, done, _ = env.step(action)\n",
    "\n",
    "            # Adjust reward based on car position\n",
    "            reward = state_1[0] + 0.5\n",
    "            # Adjust reward for task completion\n",
    "            if state_1[0] >= 0.5:\n",
    "                reward += 1\n",
    "\n",
    "            # Find max Q for t+1 state\n",
    "            if turn1:\n",
    "                Q1 = policy2(Variable(torch.from_numpy(state_1).type(torch.FloatTensor))).detach()\n",
    "                Q2 = policy1(Variable(torch.from_numpy(state_1).type(torch.FloatTensor))).detach()\n",
    "            else:\n",
    "                Q1 = policy1(Variable(torch.from_numpy(state_1).type(torch.FloatTensor))).detach()\n",
    "                Q2 = policy2(Variable(torch.from_numpy(state_1).type(torch.FloatTensor))).detach()\n",
    "            \n",
    "            _, a_prime = torch.max(Q1, -1)\n",
    "            \n",
    "            maxQ1 = Q2[a_prime]\n",
    "\n",
    "            # Create target Q value for training the policy\n",
    "            Q_target = Q.clone()\n",
    "            Q_target = Variable(Q_target)\n",
    "            Q_target[action] = reward + torch.mul(maxQ1.detach(), gamma)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = loss_fn(Q, Q_target)\n",
    "\n",
    "            # Update policy\n",
    "            policy1.zero_grad()\n",
    "            policy2.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            episode_loss += loss.item()\n",
    "            episode_reward += reward\n",
    "\n",
    "            if done:\n",
    "                if state_1[0] >= 0.5:\n",
    "                    # On successful epsisodes, adjust the following parameters\n",
    "                    # Adjust epsilon\n",
    "                    epsilon *= .95\n",
    "\n",
    "                    # Adjust learning rate\n",
    "                    scheduler.step()\n",
    "\n",
    "                    # Record successful episode\n",
    "                    successes += 1\n",
    "\n",
    "                # Record history\n",
    "                loss_history.append(episode_loss)\n",
    "                reward_history.append(episode_reward)\n",
    "                position.append(state_1[0])\n",
    "\n",
    "                break\n",
    "            else:\n",
    "                state = state_1\n",
    "\n",
    "    print('successful episodes: {:d} - {:.4f}%'.format(successes, successes/episodes*100))\n",
    "    return position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0ec76bf9b94a2d969c8300d349accf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:35<00:00, 10.68it/s]\n",
      "  0%|          | 2/1000 [00:00<01:29, 11.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful episodes: 0 - 0.0000%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 215/1000 [00:20<01:09, 11.25it/s]"
     ]
    }
   ],
   "source": [
    "EPISODES = 1000\n",
    "RUNS = 1\n",
    "\n",
    "q_data_pos = np.zeros((RUNS, EPISODES))\n",
    "dq_data_pos = np.zeros((RUNS, EPISODES))\n",
    "\n",
    "for i in tqdm_notebook(range(RUNS)):\n",
    "    position = DQN(EPISODES)\n",
    "    q_data_pos[i, :] = position\n",
    "\n",
    "    position = DoubleDQN(EPISODES)\n",
    "    dq_data_pos[i, :] = position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot percentage actions left over episodes:\n",
    "plt.plot(q_data_pos.mean(0), label='Q-learning')\n",
    "plt.plot(dq_data_pos.mean(0), label='Double Q-learning')\n",
    "plt.title('End position')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
